{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input/output\n",
    "============\n",
    "\n",
    "Requirements\n",
    "------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This libraries have to be installed on your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import silx\n",
    "import fabio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDF using FabIO\n",
    "===============\n",
    "\n",
    "For simple access, or fast access to raster format like EDF, MSK, TIFF... we recommand to use fabio `fabio`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading files\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "\n",
    "image = fabio.open(\"data/medipix.edf\")\n",
    "\n",
    "# here is the data as a numpy array\n",
    "image.data\n",
    "print(\"Image size:\", image.data.shape)\n",
    "\n",
    "# here is the header as key-value dictionary\n",
    "image.header\n",
    "print(\"Metadata count:\", len(image.header))\n",
    "print(\"Metadata names:\", list(image.header.keys()))\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with it. You can see, it is easy to access to the image data, it is easy to access to simple metadata like *pixel size*. It is more difficult to access to motors or counters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing files\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "import numpy\n",
    "\n",
    "image = numpy.random.rand(10, 10)\n",
    "metadata = {'pixel_size': '0.2'}\n",
    "\n",
    "image = fabio.edfimage.edfimage(data=image, header=metadata)\n",
    "image.write('new.edf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert files\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "\n",
    "image = fabio.open('data/medipix.edf')\n",
    "image = image.convert('tif')\n",
    "image.save('filename.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 valls valls 132951 Sep 18 16:11 \u001b[0m\u001b[01;35mfilename.tif\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls -al filename.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 using h5py\n",
    "===============\n",
    "\n",
    "Read example\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First children: ['diff_map_0000', 'diff_map_0001', 'diff_map_0002', 'diff_map_0003', 'diff_map_0004']\n",
      "Dataset: (29, 78, 100) 226200 float32\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "h5file = h5py.File('data/test.h5')\n",
    "\n",
    "# print available names at the first level\n",
    "print(\"First children:\", list(h5file['/'].keys()))\n",
    "\n",
    "# reaching a dataset from a sub group\n",
    "dataset = h5file['/diff_map_0000/data/map']\n",
    "\n",
    "# using size and types to not read the full stored data\n",
    "print(\"Dataset:\", dataset.shape, dataset.size, dataset.dtype)\n",
    "\n",
    "# datasets mimics numpy-array\n",
    "# read and apply the operation\n",
    "a = 2 * dataset[0, 5]\n",
    "# copy the data and store it as a numpy-array\n",
    "b = dataset[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write example\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "\n",
    "data = numpy.arange(10000.0)\n",
    "data.shape = 100, 100\n",
    "\n",
    "# write\n",
    "h5file = h5py.File('my_first_one.h5', mode='w')\n",
    "\n",
    "# write data into a dataset from the root\n",
    "h5file['/data1'] = data\n",
    "\n",
    "# write data into a dataset from group1\n",
    "h5file['/group1/data2'] = data\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using silx io\n",
    "============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`silx.io` provides a common API to read spec files, EDF, TIFF, and h5py files. This API is a read-only `h5py`-like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`h5ls` allow you to display the tree contained into an HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import silx.io\n",
    "import silx.io.utils\n",
    "\n",
    "h5file = silx.io.open('data/test.h5')\n",
    "\n",
    "string = silx.io.utils.h5ls(h5file)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read spec files using silx\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First childs: ['94.1', '95.1', '96.1']\n",
      "Containt of measurement: ['delta', 'H', 'K', 'L', 'Epoch', 'Seconds', 'Detector', 'Ion_m1', 'Ion_m2', 'srcur', 'curratt', 'ratio', 'all1', 'psd1', 'dir1', 'refl1', 'yoneda1', 'ACEdet', 'mcaLt1', 'twago', 'bpmi', 'tlangm', 'vO2', 'apdcnt', 'apdtemp', 'Monitor', 'detcorr', 'mca_0']\n",
      "(2011829.0, 6.2475021e-07)\n",
      "(2011831.0, 6.2534571e-07)\n",
      "(2011833.0, 6.2587151e-07)\n",
      "(2011836.0, 6.258831e-07)\n",
      "(2011838.0, 6.2555091e-07)\n",
      "(2011840.0, 6.2535531e-07)\n",
      "(2011842.0, 6.2575771e-07)\n",
      "(2011844.0, 6.2563299e-07)\n",
      "(2011846.0, 6.2574901e-07)\n",
      "(2011848.0, 6.2576453e-07)\n",
      "(2011851.0, 6.2569779e-07)\n",
      "(2011853.0, 6.2594449e-07)\n",
      "(2011855.0, 6.2583979e-07)\n",
      "(2011857.0, 6.2573582e-07)\n",
      "(2011859.0, 6.2581711e-07)\n",
      "(2011861.0, 6.257585e-07)\n",
      "(2011863.0, 6.2580352e-07)\n",
      "(2011866.0, 6.2588401e-07)\n",
      "(2011868.0, 6.2564612e-07)\n",
      "(2011870.0, 6.2587151e-07)\n",
      "(2011872.0, 6.2575191e-07)\n"
     ]
    }
   ],
   "source": [
    "import silx.io\n",
    "data = silx.io.open('data/oleg.dat')\n",
    "\n",
    "# print available scans\n",
    "print(\"First childs:\", data['/'].keys())\n",
    "\n",
    "# print available measurements from the scan 94.1\n",
    "print(\"Containt of measurement:\", data['/94.1/measurement'].keys())\n",
    "\n",
    "# get data from measurement\n",
    "xdata = data['/94.1/measurement/Epoch']\n",
    "ydata = data['/94.1/measurement/bpmi']\n",
    "for row in zip(xdata, ydata):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert spec file to HDF5\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from silx.io.spectoh5 import write_spec_to_h5\n",
    "\n",
    "write_spec_to_h5('data/oleg.dat', 'oleg.h5', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 valls valls 421152 Sep 18 16:14 oleg.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls -al oleg.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read EDF file using silx\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 6\n",
      "Size of an image: (540, 640)\n",
      "(1465802989.9281001, 0.0, 0)\n",
      "(1465803040.360028, 14.371199607849121, 0)\n",
      "(1465803090.7809851, 28.742399215698242, 0)\n",
      "(1465803140.6969931, 42.969887999999997, 0)\n",
      "(1465803191.6208999, 57.484798431396484, 0)\n",
      "(1465803266.2914319, 71.856002807617188, 0)\n"
     ]
    }
   ],
   "source": [
    "import silx.io\n",
    "data = silx.io.open('data/ID16B_diatomee.edf')\n",
    "\n",
    "# Access to the frames\n",
    "frames = data['/scan_0/instrument/detector_0/data']\n",
    "len(frames)  # number of frames\n",
    "frames[0]    # first frame\n",
    "print(\"Number of frames:\", len(frames))\n",
    "print(\"Size of an image:\", frames[0].shape)\n",
    "\n",
    "# Access to motors, monitor, timestanp\n",
    "srot = data['scan_0/instrument/positioners/srot'][...]\n",
    "mon = data['scan_0/measurement/mon'][...]\n",
    "timestamp = data['scan_0/instrument/detector_0/others/time_of_day'][...]\n",
    "for row in zip(timestamp, srot, mon):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read HDF5 using silx\n",
    "--------------------\n",
    "\n",
    "For conveniance, ``silx`` also provides the h5py API for HDF5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First children: ['diff_map_0000', 'diff_map_0001', 'diff_map_0002', 'diff_map_0003', 'diff_map_0004']\n",
      "Dataset: (29, 78, 100) 226200 float32\n"
     ]
    }
   ],
   "source": [
    "import silx.io\n",
    "\n",
    "h5file = silx.io.open('data/test.h5')\n",
    "\n",
    "# print available names at the first level\n",
    "print(\"First children:\", list(h5file['/'].keys()))\n",
    "\n",
    "# reaching a dataset from a sub group\n",
    "dataset = h5file['/diff_map_0000/data/map']\n",
    "\n",
    "# using size and types to not read the full stored data\n",
    "print(\"Dataset:\", dataset.shape, dataset.size, dataset.dtype)\n",
    "\n",
    "# datasets mimics numpy-array\n",
    "# read and apply the operation\n",
    "a = 2 * dataset[0, 5]\n",
    "# copy the data and store it as a numpy-array\n",
    "b = dataset[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "========\n",
    "\n",
    "1. Read the EDF file ``medipix.edf``.\n",
    "2. Process the data\n",
    "\n",
    "   - Create a mask for all the values below 10%.\n",
    "   - With the above mask, set the affected pixels to 10%.\n",
    "   - Optionally do the same for values above 90%.\n",
    "   - This clamp values between 10% and 90%\n",
    "\n",
    "3. Store the source, the mask of changed pixels and the result inside ``process.h5``, as below.\n",
    "\n",
    "   ![Output file structure](images/exercise-result.png)\n",
    "\n",
    "4. Load ``process.h5`` and list the root content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data/medipix.edf\n",
    "# ...\n",
    "\n",
    "# Process the data\n",
    "# ...\n",
    "\n",
    "# Load process.h5 to write inside: the source, the mask and the result\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
