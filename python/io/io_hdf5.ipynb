{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "The slides should be fine if the zoom is 200%. You will need at least this level, as the screen in MD 1-21 is relatively small and difficult to see from the back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Data IO (input/output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "ESRF data (used to) come in (too many) different formats:\n",
    "\n",
    "* Specfile, EDF, HDF5\n",
    "* and specific detector formats: MarCCD, Pilatus CBF, Dectris Eiger, â€¦\n",
    "\n",
    "\n",
    "HDF5 is now the standard ESRF data format, so we will only focus on it today.\n",
    "\n",
    "Methods for accessing other file formats are described in the [io_spec_edf.ipynb](io_spec_edf.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What is HDF5?\n",
    "\n",
    "[HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) (for Hierarchical Data Format version 5) is a file format to structure and store complex and large volumes of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## Why HDF5?\n",
    "\n",
    "* high-performance (binary)\n",
    "* portable file format \n",
    "* self-describing extensible types, rich metadata\n",
    "* support data compression\n",
    "* free (& open source)\n",
    "* widely used in scientific computing\n",
    "* adopted by many institutes (NASA, LIGO, ...)\n",
    "* adopted by most of the synchrotrons (ESRF, SOLEIL, Desy ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## HDF5 data structure overview\n",
    "\n",
    "HDF5 organizes data in a hierarchical structure, similar to a file system. Data can be almost anything: images, tables, graphs, and documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "\n",
    "The HDF5 container consists of the following main components:\n",
    "\n",
    "- **File**: the root of the container, which serves as the top-level node.\n",
    "- **Group**: a hierarchical grouping structure containing other groups or datasets that organize and categorize data.\n",
    "- **Dataset**: a multidimensional array of data elements, representing a collection of values stored in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Additionally, HDF5 features include:\n",
    "\n",
    "- **Links**: references to other files or datasets within the container.\n",
    "- **Attributes**: metadata associated with a dataset or group.\n",
    "- **Datatypes**: definitions for the structure and storage format of data.\n",
    "- **Virtual datasets**: interfaces that provide access to data without storing it in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## An HDF5 example\n",
    "\n",
    "Here is an example of the file generated by [pyFAI](https://github.com/silx-kit/pyFAI).\n",
    "\n",
    "![hdf5_example](images/hdf5_example.png \"hdf5 example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Useful tools for inspecting HDF5 files\n",
    "\n",
    "### [HDFGroup tools for viewing and editing HDF5](https://support.hdfgroup.org/documentation/hdf5/latest/_view_tools.html)\n",
    "\n",
    "Command line and desktop application: `h5ls`, `h5dump`, `hdfview`\n",
    "\n",
    "```bash\n",
    ">>> h5ls -r my_first_one.h5\n",
    "    /                        Group\n",
    "    /data1                   Dataset {100, 100}\n",
    "    /group1                  Group\n",
    "    /group1/data2            Dataset {100, 100}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### [`h5glance`](https://github.com/European-XFEL/h5glance)\n",
    "\n",
    "Jupyter notebook and command line tool for browsing HDF5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From the Jupyter notebook.\n",
    "from h5glance import H5Glance\n",
    "\n",
    "H5Glance(\"data/water.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From the command line.\n",
    "!h5glance data/water.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### [`jupyterlab-h5web`](https://github.com/silx-kit/jupyterlab-h5web/)\n",
    "\n",
    "JupyterLab extension to explore and visualize HDF5\n",
    "file contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jupyterlab_h5web import H5Web\n",
    "\n",
    "H5Web(\"data/water.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### [`silx view`](http://www.silx.org/doc/silx/latest/applications/view.html)\n",
    "\n",
    "Desktop application file browser/viewer\n",
    "\n",
    "```bash\n",
    "pip install silx\n",
    "silx view my_file.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!silx view data/water.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What is h5py?\n",
    "\n",
    "[h5py](https://www.h5py.org/) is a Python binding for accessing HDF5 files. \n",
    "\n",
    "It allows the reading/writing of HDF5 files using a simple Pythonic interface.\n",
    "\n",
    "Originally written by [Andrew Collette](http://shop.oreilly.com/product/0636920030249.do).\n",
    "\n",
    "![h5py book](images/h5py.png \"h5py book\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## How to install h5py?\n",
    "\n",
    "```bash\n",
    "pip install h5py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "print(\"h5py:\", h5py.version.version)\n",
    "print(\"hdf5:\", h5py.version.hdf5_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Opening and creating HDF5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### `h5py.File`\n",
    "\n",
    "* First open the file with [h5py.File](http://docs.h5py.org/en/stable/high/file.html):\n",
    "\n",
    "    ```\n",
    "    h5py.File('myfile.hdf5', mode)\n",
    "    ```\n",
    "\n",
    "* [Opening modes](http://docs.h5py.org/en/stable/high/file.html#opening-creating-files):\n",
    "\n",
    "| Mode    | Meaning                                                            |\n",
    "|---------|--------------------------------------------------------------------|\n",
    "| r       | Read-only, file must exist; *default with h5py* **v3**             |\n",
    "| r+      | Read/write, file must exist                                        |\n",
    "| w       | Create file, truncate if exists                                    |\n",
    "| w- or x | Create file, fail if exists                                        |\n",
    "| a       | Read/write if exists, create otherwise; *default with h5py* **v2** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Opening an existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5file = h5py.File(\"data/water.h5\", mode=\"r\")\n",
    "...\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Creating a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5file = h5py.File(\"data/new_data.h5\", mode=\"w\")\n",
    "...\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Using a context manager\n",
    "\n",
    "* Context managers guarantee that resources are released. In our case, it ensures that the HDF5 file is closed.\n",
    "* Usually used from the `with` statement.\n",
    "\n",
    "To safely access a HDF5 file, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"data/water.h5\", mode=\"r\") as h5file:\n",
    "    print(h5file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### File structure\n",
    "\n",
    "#### `h5py.Group`\n",
    "\n",
    "Documentation: [Group](http://docs.h5py.org/en/stable/high/group.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "##### Browsing groups\n",
    "\n",
    "The file content can be accessed using a dictionary-like API, using methods like **Group.keys()**, **Group.values()**, or **Group.items()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the available group names at the root level.\n",
    "with h5py.File(\"data/water.h5\", mode=\"r\") as h5file:\n",
    "    print(list(h5file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# List the children of the 'entry_0000' group.\n",
    "with h5py.File(\"data/water.h5\", mode=\"r\") as h5file:\n",
    "    h5group = h5file[\"entry_0000\"]\n",
    "    pprint(dict(h5group.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "##### Creating a group\n",
    "\n",
    "Documentation: [Group.create_group](https://docs.h5py.org/en/stable/high/group.html#h5py.Group.create_group):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List 'entry_0000' group children.\n",
    "with h5py.File(\"data/new_data.h5\", mode=\"w\") as h5file:\n",
    "    my_h5group = h5file.create_group(\"my_h5group\")\n",
    "    my_h5subgroup = my_h5group.create_group(\"my_h5subgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "H5Glance(\"data/new_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### `h5py.Dataset`\n",
    "\n",
    "Documentation: [Dataset](http://docs.h5py.org/en/stable/high/dataset.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "##### Reading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "This is probably the most common task when dealing with HDF5 files. \n",
    "\n",
    "Note that datasets have properties similar to those of the NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"data/water.h5\", mode=\"r\") as h5file:\n",
    "    h5dataset = h5file[\"/entry_0000/4_azimuthal_integration/results/I\"]\n",
    "    print(\"h5dataset:\", h5dataset.shape, h5dataset.dtype, h5dataset.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "You can copy the data to a NumPy array using one of the following ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with h5py.File(\"data/water.h5\", mode=\"r\") as h5file:\n",
    "    h5dataset = h5file[\"/entry_0000/4_azimuthal_integration/results/I\"]\n",
    "    data = h5dataset[()] # Recommended. Copy the dataset to a NumPy array.\n",
    "    data = h5dataset[...] # Same as above.\n",
    "    data = np.array(h5dataset) # Another way.\n",
    "    data = h5dataset[:] # This also works, but avoid it as it fails in some cases.\n",
    "    print(\"data type:\", type(data), \"; shape\", data.shape, \"; min.:\", data.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Note that once the file is closed, the `h5dataset` object will be unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"data/water.h5\", mode=\"r\") as h5file:\n",
    "    h5dataset = h5file[\"/entry_0000/4_azimuthal_integration/results/I\"]\n",
    "    data = h5dataset[()]  # Copy the whole dataset to a NumPy array.\n",
    "print(h5dataset) # Not available anymore, but the copied data is.\n",
    "print(data[:5]) # Print the first five elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Not very convenient for interactive browsing... this is why silx view, h5web, h5glance ... exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "##### Writing a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "h5py will create all missing groups to solve the dataset location. So you usually won't have to call *create_group*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"data/new_data.h5\", mode=\"a\") as h5file:\n",
    "    h5file[\"my_h5group/to/my_h5dataset\"] = np.random.rand(100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Alternative: using [Group.create_dataset](https://docs.h5py.org/en/stable/high/group.html#h5py.Group.create_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"data/new_data.h5\", mode=\"w\") as h5file:\n",
    "    h5file.create_dataset(\"my_data\", data=np.arange(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "H5Glance(\"data/new_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "[Attributes](https://docs.h5py.org/en/stable/high/attr.html) are the way to store metadata for a [group](https://docs.h5py.org/en/stable/high/group.html) or a [dataset](https://docs.h5py.org/en/stable/high/dataset.html).\n",
    "\n",
    "Group and dataset have a small `'<obj>.attrs'` attached.\n",
    "\n",
    "**Warning** attributes must be of a limited size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "##### Writing an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"data/new_data.h5\", \"w\") as h5file:\n",
    "    dataset = h5file.create_dataset(\"my_dataset\", data=np.random.rand(10, 10))\n",
    "    dataset.attrs[\"description\"] = \"This is a random dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "##### Reading an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"data/new_data.h5\", \"r\") as h5file:\n",
    "    print(h5file[\"my_dataset\"].attrs[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exercise: Flat field correction\n",
    "\n",
    "Flat-field correction is a technique used to improve quality in digital imaging.\n",
    "\n",
    "The goal is to normalize images and remove artifacts caused by variations in the pixel-to-pixel sensitivity of the detector and/or by distortions in the optical path. (see https://en.wikipedia.org/wiki/Flat-field_correction)\n",
    "\n",
    "$$ normalized = \\frac{raw - dark}{flat - dark} $$\n",
    "\n",
    "* `normalized`: Image after flat field correction\n",
    "* `raw`: Raw image. It is acquired with the sample.\n",
    "* `flat`: Flat field image. It is the response given out by the detector for a uniform input signal. This image is acquired without the sample.\n",
    "* `dark`: Also named `background` or `dark current`. It is the response given out by the detector when there is no signal. This image is acquired without the beam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Here is a function implementing the flat field correction:\n",
    "\n",
    "*Note: make sure you execute the cell for defining this function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def flatfield_correction(raw, flat, dark):\n",
    "    \"\"\"\n",
    "    Apply a flat-field correction to a raw data using a flat and a dark.\n",
    "    \"\"\"\n",
    "    # Make sure that the computation is done using float\n",
    "    # to avoid type overflow or loss of precision\n",
    "    raw = raw.astype(np.float32)\n",
    "    flat = flat.astype(np.float32)\n",
    "    dark = dark.astype(np.float32)\n",
    "    # Do the computation\n",
    "    return (raw - dark) / (flat - dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "If you like to plot an image, you can use `matplotlib`'s `imshow` function.\n",
    "\n",
    "The `%matplotlib` \"magic\" command should be called once first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.random.random((20, 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "1. Browse the file ``data/ID16B_diatomee.h5``.\n",
    "2. Get **a single** raw dataset, a flat field dataset, and a dark image dataset from this file.\n",
    "3. Apply the flat field correction.\n",
    "4. Save the result into a new HDF5 file.\n",
    "\n",
    "If you are stuck, the solution is provided in the file [solutions/exercise1.py](./solutions/exercise1.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jupyterlab_h5web import H5Web\n",
    "\n",
    "H5Web(\"data/ID16B_diatomee.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(\"data/ID16B_diatomee.h5\", mode=\"r\") as h5s:\n",
    "    pass\n",
    "    # Step 1: Read the data.\n",
    "\n",
    "    # raw_data_path = ...\n",
    "    # raw_data = ...\n",
    "\n",
    "    # flat_path = ...\n",
    "    # flat = ...\n",
    "\n",
    "    # dark_path = ...\n",
    "    # dark = ...\n",
    "\n",
    "# Step 2: Compute the result.\n",
    "\n",
    "# normalized = flatfield_correction(raw_data, flat, dark)\n",
    "\n",
    "# Step 3: Save the result.\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "1. Apply the flat field correction **to all** raw data available (use the same flat and dark for all the images).\n",
    "2. Save each result into different datasets of the same HDF5 file.\n",
    "\n",
    "If you are stuck, the solution is provided in the file [solutions/exercise2.py](./solutions/exercise2.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "From the previous exercise, we can see that the flat field correction was not very good for the last images.\n",
    "\n",
    "Another flat field was acquired at the end of the acquisition.\n",
    "\n",
    "We could use this information to compute a flat field closer to the image we want to normalize. This can be done with a linear interpolation of the flat images by using the name of the image as the interpolation factor (which varies between 0 and 500 in this case).\n",
    "\n",
    "1. For each raw data, compute the corresponding flat field using linear interpolation (between `flatfield/0000` and `flatfield/0500`).\n",
    "2. Save each result into different datasets in a single HDF5 file.\n",
    "\n",
    "If you are stuck, the solution is provided in the file [solutions/exercise3.py](./solutions/exercise3.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Dataset compression\n",
    "\n",
    "Install [hdf5plugin](https://github.com/silx-kit/hdf5plugin) and `import hdf5plugin`.\n",
    "\n",
    "HDF5 provides dataset compression support.\n",
    "With `h5py` GZIP and LZF compression are available (see [compression-filters](https://docs.h5py.org/en/stable/high/dataset.html#lossless-compression-filters)).\n",
    "Yet, there are many [third-party compression filters for HDF5](https://portal.hdfgroup.org/display/support/Registered+Filter+Plugins) available.\n",
    "\n",
    "[hdf5plugin](https://github.com/silx-kit/hdf5plugin) allows usage of some of those compression filters with `h5py` (Blosc, Blosc2, BitShuffle, BZip2, FciDecomp, LZ4, SZ, SZ3, Zfp, ZStd).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import hdf5plugin  # Allows to read dataset stored with supported compressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "To write compressed datasets, see:\n",
    "\n",
    "- [Group.create_dataset](https://docs.h5py.org/en/stable/high/group.html#h5py.Group.create_dataset) `chunks`, `compression` and `compression_opts` parameters.\n",
    "- [\"Chunked Storage\" documentation](https://docs.h5py.org/en/stable/high/dataset.html#chunked-storage)\n",
    "- [hdf5plugin documentation](https://github.com/silx-kit/hdf5plugin#documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Soft and external links\n",
    "\n",
    "A HDF5 file can contain links to Group/Dataset:\n",
    "- within the same file: see [h5py.SoftLink](https://docs.h5py.org/en/stable/high/group.html#soft-links)\n",
    "- in another file: see [h5py.ExternalLink](https://docs.h5py.org/en/stable/high/group.html#external-links)\n",
    "\n",
    "Links can be dangling if the destination does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### External dataset\n",
    "\n",
    "A HDF5 file can contain datasets that are stored in external binary files: See [Group.create_dataset](https://docs.h5py.org/en/stable/high/group.html#h5py.Group.create_dataset) `external` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Virtual Dataset (aka. VDS)\n",
    "\n",
    "Virtual dataset allows to map multiple datasets into a single one.\n",
    "Once created it behaves as other datasets.\n",
    "\n",
    "See https://docs.h5py.org/en/stable/vds.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### HDF5 file locking: A word of caution\n",
    "\n",
    "Do **NOT** open an HDF5 file that is currently being written (without caution).\n",
    "\n",
    "By default, HDF5 locks the file even for reading, and other processes cannot open it for writing. \n",
    "This can be an issue, e.g., during acquisition.\n",
    "\n",
    "**Warning**: Do not open the same file twice for writing without file locking, or the file will be corrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Workarounds:\n",
    "\n",
    "- Helper to handle HDF5 file locking: [`silx.io.h5py_utils.File`](http://www.silx.org/doc/silx/latest/modules/io/h5py_utils.html#silx.io.h5py_utils.File).\n",
    "- HDF5 file locking can be disabled by setting the `HDF5_USE_FILE_LOCKING` environment variable to `FALSE`.\n",
    "- With recent version of `h5py` (>= v3.5.0): [`h5py.File`'s `locking` argument](https://github.com/h5py/h5py/blob/f155036478ca458924d2c46edfd6bfb9e6e32fb5/h5py/_hl/files.py#L443-L451)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Chunked storage\n",
    "\n",
    "By default, HDF5 datasets will be contiguous (like C). If you have specific usages or want to improve speed, you may want to define chunks. See [h5py chunked storage](https://docs.h5py.org/en/stable/high/dataset.html#chunked-storage) (for advanced usage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Practical tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Conversion:\n",
    "    - [`silx convert`](http://www.silx.org/doc/silx/latest/applications/convert.html): To convert EDF, or spec files to HDF5\n",
    "\n",
    "- Reading/writing HDF5 helpers:\n",
    "    - [`silx.io.dictdump`](http://www.silx.org/doc/silx/latest/modules/io/dictdump.html): `h5todict`, `dicttoh5`\n",
    "    - [`silx.io.utils.h5py_read_dataset`](http://www.silx.org/pub/doc/silx/latest/modules/io/utils.html#silx.io.utils.h5py_read_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### A word about NeXus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "[Nexus](https://www.nexusformat.org/) is a data format for neutron, x-ray, and muon science.\n",
    "\n",
    "It aims to be a common data format for scientists for greater collaboration.\n",
    "\n",
    "If you intend to store some data to be shared, it can give you a \"standard way\" for storing it.\n",
    "\n",
    "The main advantage is to ensure compatibility between your data files and existing software packages (if they respect the NeXus convention) or from your software to different datasets:\n",
    "\n",
    "* an example on [how to store tomography raw data](http://download.nexusformat.org/doc/html/classes/applications/NXtomo.html?highlight=tomography)\n",
    "* an example to store [tomoraphy application (3D reconstruction)](http://download.nexusformat.org/doc/html/classes/applications/NXtomoproc.html?highlight=tomography).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "[h5py](https://www.h5py.org/) provides access to HDF5 file content from Python through:\n",
    "\n",
    "- [`h5py.File`](https://docs.h5py.org/en/stable/high/file.html) opens a HDF5 file:\n",
    "  - Do not forget the mode: `'r'`, `'a'`, `'w'`.\n",
    "  - Use a `with` statement, or do not forget to `close` the file.\n",
    "- [`h5py.Group`](https://docs.h5py.org/en/stable/high/group.html) provides a key-value mapping `dict`-like access to the HDF5 structure.\n",
    "- [`h5py.Dataset`](https://docs.h5py.org/en/stable/high/dataset.html) gives access to data as `numpy.ndarray`."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
